# rlcourse-march-10-dy4242407
rlcourse-march-10-dy4242407 created by GitHub Classroom

In this assignment, I explored SARSA, expected SARSA, Q-learning, and double Q-learning on two domains (a simple maze and the cliff walking problem). I first explored the bias-variance trade-off in Expected SARSA vs. SARSA by presenting the variance analysis from section 5 in the paper "A Theoretical and Empirical Analysis of Expected Sarsa". Then the results of these four algorithms on the simple maze and cliff walking problem are presented. The empirical results support the paper's claim that the expected SARSA learns faster than SARSA on some domains. On the other side, I notice that in some domains (like the Maximization Bias Example or the cliff walking), double Q-learning perform better than Q-learning. It is also interesting to discover that the optimal paths found by different algorithms are very different in cliff walking problem.
